# ğŸ¤– Puppeteer Service

The **Puppeteer Service** is a headless browser scraper built on **Chrome + Puppeteer**.  
It powers data collection by scraping links and content from multiple sources depending on the request.  

âœ¨ Use case scenarios:
- ğŸ” **Search Engine Scraping** â€“ fetch all links from [search.brave.com](https://search.brave.com) (default configured).  
- ğŸŒ **External URL Scraping** â€“ scrape content directly from URLs if an `_external` database is already built in TiDB.  
- ğŸ¢ **Internal Knowledge Base Scraping** â€“ crawl internal company websites for knowledge-based content.  

---

## ğŸš€ Getting Started

### Download the Image

```bash
docker pull ghcr.io/hendram/puppeteerservice
```
â–¶ï¸ Start

```bash
docker run -it -d --network=host ghcr.io/hendram/puppeteerservice bash
```

ğŸ” Check Running Container

```bash
docker ps
```

```bash
CONTAINER ID   IMAGE                                 NAME              STATUS
123abc456def   ghcr.io/hendram/puppeteerservice      pedantic_payne    Up 5 minutes
```

ğŸ“¦ Enter Container

```bash
docker exec -it infallible_mclean /bin/bash
```

ğŸƒ Run the Service

```bash
cd /home/browserconnsvc
node index.js
```

## âš™ï¸ How It Works

Every job starts from the **backend (`chunkgeneratorforaimodel`)** and flows through the Puppeteer Service.  
Depending on the type of request, the service decides what to scrape:  

1. ğŸ“© **Receive Job**  
   The backend sends a request to the Puppeteer Service with scraping instructions.  

2. ğŸ”€ **Decision Stage**  
   The service chooses the scraping mode:  
   - ğŸŸ£ **Search Engine Mode** â†’ Collects links from [Brave Search](https://search.brave.com).  
   - ğŸ”µ **External Mode** â†’ Scrapes a target URL if `_external` data already exists in **TiDB**.  
   - ğŸŸ¢ **Internal Mode** â†’ Crawls internal company knowledge base websites.  

3. ğŸ“¤ **Return Results**  
   Once scraping is complete, the extracted data is sent back to the backend for processing, storage, or downstream AI models.  
