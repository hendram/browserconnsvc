# ğŸ¤– Puppeteer Service

The **Puppeteer Service** is a headless browser scraper built on **Chrome + Puppeteer**.  
It powers data collection by scraping links and content from multiple sources depending on the request.  

âœ¨ Use case scenarios:
- ğŸ” **Search Engine Scraping** â€“ fetch all links from [search.brave.com](https://search.brave.com) (default configured).  
- ğŸŒ **External URL Scraping** â€“ scrape content directly from URLs if an `_external` database is already built in TiDB.  
- ğŸ¢ **Internal Knowledge Base Scraping** â€“ crawl internal company websites for knowledge-based content.  

---

## ğŸš€ Getting Started

### Download the Image

```bash
docker pull ghcr.io/hendram/puppeteerservice
```
â–¶ï¸ Start

```bash
docker run -it -d --network=host ghcr.io/hendram/puppeteerservice bash
```

ğŸ” Check Running Container

```bash
docker ps
```

```bash
CONTAINER ID   IMAGE                                 NAME              STATUS
123abc456def   ghcr.io/hendram/puppeteerservice      pedantic_payne    Up 5 minutes
```

ğŸ“¦ Enter Container

```bash
docker exec -it infallible_mclean /bin/bash
```

ğŸƒ Run the Service

```bash
cd /home/browserconnsvc
node index.js
```

How It Works

Backend Request â†’ The service first receives jobs from chunkgeneratorforaimodel.

Decision Flow:

Scrape search engine links only ğŸŸ£

Scrape external site (if _external DB is built on TiDB) ğŸ”µ

Scrape internal company knowledge base ğŸŸ¢

Return Data â†’ Results are sent back to the backend for further processing.

